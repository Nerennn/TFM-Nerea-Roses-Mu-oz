{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc8b772",
   "metadata": {},
   "source": [
    "# Modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a55f4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Cargar el modelo y el tokenizer de RoBERTuito entrenado para análisis de sentimiento\n",
    "modelo = \"pysentimiento/robertuito-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modelo)\n",
    "\n",
    "# Crear pipeline para clasificación\n",
    "analizador = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64a3b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEG', 'score': 0.9645105600357056}]\n",
      "[{'label': 'POS', 'score': 0.9567092061042786}]\n",
      "[{'label': 'NEU', 'score': 0.560903787612915}]\n"
     ]
    }
   ],
   "source": [
    "# Frase de ejemplo\n",
    "frase1 = \"Estoy harto de todo esto\"\n",
    "frase2 = \"Me encanta la programación en Python\"\n",
    "frase3 = \"Hoy hace sol\"\n",
    "\n",
    "# Clasificar\n",
    "resultado = analizador(frase1)\n",
    "print(resultado)\n",
    "resultado = analizador(frase2)\n",
    "print(resultado)\n",
    "resultado = analizador(frase3)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474e6fd",
   "metadata": {},
   "source": [
    "Como se puede apreciar, el modelo de red neuronal da una salida del tipo:\n",
    "- (sentimiento, score)\n",
    "donde sentimiento puede ser NEG (negativo), NEU (neutral) o POS (positivo) y score es un número entre 0 y 1, indicando una puntuación asignada por el modelo al sentimiento inferido.\n",
    "\n",
    "Por tanto, no se trata de un modelo de regresión, o de clasificación binaria, sino de un modelo de clasificación multiclase, donde la salida es la tupla (sentimiento, score).\n",
    "\n",
    "De cara a poder agregar valores de score, es necesario transformar de acuerdo a nuestro interés. No podemos simplemente sumar los scores, ya que el score por si solo no indica el sentimiento de la frase. En nuestro caso queremos diferenciar entre sentimiento (positivo o negativo) y neutralidad. Por tanto, tiene sentido utilizar el score como un peso y asignar un valor numérico a las etiquetas:\n",
    "\n",
    "- NEG = 1\n",
    "- NEU = -1\n",
    "- POS = 1\n",
    "\n",
    "Como solo queremos diferenciar entre sentimiento y no sentimiento (para la hipótesis 3), asignamos el valor 1 a NEG y POS, y -1 a NEU. De esta forma, si la frase es positiva o negativa, el score se suma al resultado final, mientras que si es neutral, se resta.\n",
    "\n",
    "Cada frase quedaría entonces caracterizada por la tupla (sentimiento, score) y una puntuación calculada como:\n",
    "$$\n",
    "\\text{puntuacion} = \\text{sentimiento} \\cdot \\text{score} \n",
    "$$\n",
    "siendo sentimiento el valor numérico asignado a la etiqueta (-1 o 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20312aef",
   "metadata": {},
   "source": [
    "# Prueba del modelo con datos ficticios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un conjunto de datos de ejemplo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lider_a_partido={}\n",
    "data = pd.read_csv(\"base_conjunta.csv\")\n",
    "# data[\"Partido\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32394bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lider_a_partido ={'Santiago Abascal':\"VOX\", 'Feijóo':\"PP\", 'Pedro Sánchez':\"PSOE\", 'PP':\"PP\", 'PSOE':\"PSOE\",\n",
    "       'Sumar':\"Sumar\", 'Yolanda Díaz':\"Sumar\", 'VOX':'VOX'}\n",
    "oposicion = set(['PP', 'VOX', 'Sumar'])\n",
    "data[\"Partido\"] = data[\"nombre\"].map(lider_a_partido)\n",
    "data[\"Oposición\"] = data[\"Partido\"].apply(lambda x: x in oposicion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ec5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Lider</th>\n",
       "      <th>body</th>\n",
       "      <th>blackout</th>\n",
       "      <th>origen</th>\n",
       "      <th>Partido</th>\n",
       "      <th>Oposición</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santiago Abascal</td>\n",
       "      <td>1927846794114859511</td>\n",
       "      <td>2025-05-28 23:57:48</td>\n",
       "      <td>si</td>\n",
       "      <td>Llevo tiempo diciendo que lo peor de Sánchez e...</td>\n",
       "      <td>0</td>\n",
       "      <td>ABASCAL</td>\n",
       "      <td>VOX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santiago Abascal</td>\n",
       "      <td>1927825174524543304</td>\n",
       "      <td>2025-05-28 22:31:53</td>\n",
       "      <td>si</td>\n",
       "      <td>Será un placer acompañarte.</td>\n",
       "      <td>0</td>\n",
       "      <td>ABASCAL</td>\n",
       "      <td>VOX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santiago Abascal</td>\n",
       "      <td>1927718717070217584</td>\n",
       "      <td>2025-05-28 15:28:52</td>\n",
       "      <td>si</td>\n",
       "      <td>Esta es la realidad: el Partido Popular (españ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ABASCAL</td>\n",
       "      <td>VOX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Santiago Abascal</td>\n",
       "      <td>1927656927925879174</td>\n",
       "      <td>2025-05-28 11:23:20</td>\n",
       "      <td>si</td>\n",
       "      <td>Periodismo lacayo que hace cualquier cosa para...</td>\n",
       "      <td>0</td>\n",
       "      <td>ABASCAL</td>\n",
       "      <td>VOX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santiago Abascal</td>\n",
       "      <td>1927430822652752036</td>\n",
       "      <td>2025-05-27 20:24:52</td>\n",
       "      <td>si</td>\n",
       "      <td>El autócrata pretende que su régimen sea perpe...</td>\n",
       "      <td>0</td>\n",
       "      <td>ABASCAL</td>\n",
       "      <td>VOX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nombre                   id            timestamp Lider  \\\n",
       "0  Santiago Abascal  1927846794114859511  2025-05-28 23:57:48    si   \n",
       "1  Santiago Abascal  1927825174524543304  2025-05-28 22:31:53    si   \n",
       "2  Santiago Abascal  1927718717070217584  2025-05-28 15:28:52    si   \n",
       "3  Santiago Abascal  1927656927925879174  2025-05-28 11:23:20    si   \n",
       "4  Santiago Abascal  1927430822652752036  2025-05-27 20:24:52    si   \n",
       "\n",
       "                                                body  blackout   origen  \\\n",
       "0  Llevo tiempo diciendo que lo peor de Sánchez e...         0  ABASCAL   \n",
       "1                        Será un placer acompañarte.         0  ABASCAL   \n",
       "2  Esta es la realidad: el Partido Popular (españ...         0  ABASCAL   \n",
       "3  Periodismo lacayo que hace cualquier cosa para...         0  ABASCAL   \n",
       "4  El autócrata pretende que su régimen sea perpe...         0  ABASCAL   \n",
       "\n",
       "  Partido  Oposición  \n",
       "0     VOX       True  \n",
       "1     VOX       True  \n",
       "2     VOX       True  \n",
       "3     VOX       True  \n",
       "4     VOX       True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafa8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 834/1087 [08:52<02:41,  1.57it/s]  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m dic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEU\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEG\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frase \u001b[38;5;129;01min\u001b[39;00m tqdm(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m----> 8\u001b[0m   resultado \u001b[38;5;241m=\u001b[39m \u001b[43manalizador\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;66;03m# Guardamos la etiqueta de sentimiento\u001b[39;00m\n\u001b[0;32m     10\u001b[0m   sentimiento\u001b[38;5;241m.\u001b[39mappend(resultado[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[1;32m--> 159\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\transformers\\pipelines\\base.py:1379\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         )\n\u001b[0;32m   1377\u001b[0m     )\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\transformers\\pipelines\\base.py:1385\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m-> 1385\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m   1386\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1387\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:183\u001b[0m, in \u001b[0;36mTextClassificationPipeline.preprocess\u001b[1;34m(self, inputs, **tokenizer_kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# This is likely an invalid usage of the pipeline attempting to pass text pairs.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe pipeline received invalid inputs, if you are trying to send text pairs, you can try to send a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dictionary `\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy text\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_pair\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy pair\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}` in order to send a text pair.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(inputs, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2887\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2887\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\nerea\\anaconda3\\envs\\sentimentanal\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2947\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   2944\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[1;32m-> 2947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2950\u001b[0m     )\n\u001b[0;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[0;32m   2953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2956\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "sentimiento = []\n",
    "score = []\n",
    "puntuacion = []\n",
    "dic = {\"NEU\":-1, \"POS\":1, \"NEG\":1}\n",
    "\n",
    "for frase in tqdm(data[\"body\"]):\n",
    "    try:\n",
    "      resultado = analizador(frase)\n",
    "    except Exception as e:\n",
    "      print(f\"Error procesando la frase: {frase}\")\n",
    "      print(f\"Error: {e}\")\n",
    "  # Guardamos la etiqueta de sentimiento\n",
    "  sentimiento.append(resultado[0]['label'])\n",
    "  # guardamos el score\n",
    "  score.append(resultado[0]['score'])\n",
    "  \n",
    "  # calculamos la puntuación multiplicando el score por el valor de la etiqueta\n",
    "  puntuacion.append(dic[resultado[0]['label']]*resultado[0]['score'])\n",
    "\n",
    "  \n",
    "data[\"Sentimiento\"] = sentimiento\n",
    "data[\"Score\"] = score\n",
    "data[\"Puntuacion\"] = puntuacion\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Resultados\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Sumamos puntuacion agrupado por partido\n",
    "print(\"Resultados por partido (sumando la puntuacion)\")\n",
    "df_partido = df.groupby(\"Partido\")[\"Puntuacion\"].sum().reset_index()\n",
    "print(df_partido)\n",
    "print(\"\\n\")\n",
    "# Sumamos puntuacion agrupado por partido y lider\n",
    "print(\"Resultados por partido y lider (sumando la puntuacion)\")\n",
    "df_partido_lider = df.groupby([\"Partido\", \"Lider\"])[\"Puntuacion\"].sum().reset_index()\n",
    "print(df_partido_lider)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20bc8e2",
   "metadata": {},
   "source": [
    "Los resultados ficticios nos indican lo siguiente:\n",
    "\n",
    "- A nivel de partido, todos los valores son positivos, indicando que en general los partidos muestra sentimientos en las frases.\n",
    "- A nivel de líderes, de nuevo todos los valores son positivos. Destacaríamos que el lider del partido A tiene un score más cercano al 0, lo que indica una carga sentimental más baja que el resto de líderes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confianza de la oposicion que sea negativo:  1.0\n",
      "Lift:  1.2\n"
     ]
    }
   ],
   "source": [
    "# Confianza de la oposicion que sea negativo\n",
    "# Tweets negativos de la oposicion\n",
    "df_oposicion = df[df[\"Oposicion\"] == True]\n",
    "df_oposicion_neg = df_oposicion[df_oposicion[\"Sentimiento\"] == \"NEG\"]\n",
    "\n",
    "\n",
    "confianza = df_oposicion_neg.shape[0] / df_oposicion.shape[0]\n",
    "print(\"Confianza de la oposicion que sea negativo: \", confianza)\n",
    "\n",
    "# Lift\n",
    "lift = confianza / (df[df[\"Sentimiento\"] == \"NEG\"].shape[0] / df.shape[0])\n",
    "print(\"Lift: \", lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985835e9",
   "metadata": {},
   "source": [
    "Hipotesis 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ps = data[data[\"nombre\"]==\"Pedro Sánchez\"]\n",
    "data_nf = data[data[\"nombre\"]==\"Feijóo\"]\n",
    "data_ab = data[data[\"nombre\"]==\"Santiago Abascal\"]\n",
    "data_yd = data[data[\"nombre\"]==\"Yolanda Díaz\"]\n",
    "data_su = data[data[\"nombre\"]==\"Sumar\"]\n",
    "data_pp = data[data[\"nombre\"]==\"PP\"]\n",
    "data_vox = data[data[\"nombre\"]==\"VOX\"]\n",
    "data_psoe = data[data[\"nombre\"]==\"PSOE\"]\n",
    "\n",
    "\n",
    "# Aplicar test de normalidad a cada dataset usando {}\n",
    "\n",
    "# Aplicar test de hipótesis por pares (en Puntuación)\n",
    "# Usando el modelo {modelo}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimentanal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
